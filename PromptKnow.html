<!DOCTYPE html>

<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>PromptKnow</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        img {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        table,
        th,
        td {
            border: 1px solid black;
            border-collapse: collapse;
        }
    </style>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- <base href="/"> -->

    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <link rel="icon" type="image/png"
        href="https://github.com/Junjue-Wang/FactSeg/blob/master/imgs/myicon.jpg?raw=true">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-3"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-110862391-3');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Knowledge is Diverse: Knowledge-Aware and Constraints <br> Prompt Learning for Vision-Language Models

                </br>
                <small>

                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        Weihao Shen
                    </li>
                    <li>
                        Ailong Ma
                    </li>
                    <li>
                        <a href="https://junjue-wang.github.io/homepage/">
                            Junjue Wang
                        </a>
                    </li>
                    <li>
                        <a href="http://zhuozheng.top/">
                            Zhuo Zheng
                        </a>
                    </li>


                    <li>
                        <a href="http://rsidea.whu.edu.cn/">
                            Yanfei Zhong
                        </a>
                    </li>

                </ul>
                <small>

                </small>
            </div>
        </div>


        <!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a
                            href="https://www.researchgate.net/publication/376519677_EarthVQA_Towards_Queryable_Earth_via_Relational_Reasoning-based_Remote_Sensing_Visual_Question_Answering">
                            <image src="research_src/EarthVQA/paper_overview.png" height="120px"></image><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a
                            href="https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-01-08/qd43oo1/Poster-AAAI.pdf">
                            <image src="research_src/EarthVQA/poster.png" height="120px"></image><br>
                            <h4><strong>Poster</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a
                            href="https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-01-08/2q83o0t/EarthVQA-video.mp4">
                            <image src="research_src/EarthVQA/video.png" height="120px"></image><br>
                            <h4><strong>Video</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <!-- <image src="research_src/EarthVQA/dataset_vis.png" class="img-responsive" alt="overview"><br></image>
                <image src="research_src/EarthVQA/framework.png" class="img-responsive" alt="overview"><br></image> -->
                <!-- <p class="text-justify">This is follow-up work of our <a
                        href="https://Junjue-Wang.github.io/homepage/LoveDA" style="color: #0000cc">LoveDA
                        (NeurIPS2021)</a>
                </p> -->
                <p class="text-justify">
                    Prompt learning is an effective way to adapt the pre-trained vision-language
                    model to the downstream task using task-related textual tokens. Conventional
                    prompt learning relies on image category information to fine-tune the
                    foundational model. Still, the lack of a comprehensive description and
                    attribute associations within category information often leads to overfitting
                    specific tasks, resulting in insufficient generalization to new tasks. This
                    research advocates injecting knowledge into language models to demonstrate its
                    potential for enhanced generalization performance on downstream tasks. We
                    propose a diverse knowledge-aware and constraints prompt learning approach
                    (PromptKnow), which optimizes the generalization performance of the model with
                    scene knowledge as the core: a) Generating attributes and description knowledge
                    of the scene for knowledge-aware prompt learning via a Large Language Model to
                    utilize external knowledge features associated with the category, b) using
                    external knowledge to constrain the model to enhance the generalization of the
                    model to novel classes and c) calibration of category probabilities through the
                    attribute and description knowledge prompt learning branch enhances the model's
                    performance on base and novel classes. We evaluate the effectiveness of our
                    approach on 15 datasets where PromptKnow performs well compared to existing
                    SOTA methods.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>

                <image src="research_src/PromptKnow/PromptKnow.jpg" class="img-responsive" alt="overview"><br></image>

                <h3>
                    Knowledge Generation Pipeline
                </h3>

                <image src="research_src/PromptKnow/KG_Gen.jpg" class="img-responsive" alt="overview"><br></image>
               
                <h3>
                    Experiments
                </h3>
                <!-- <image src="research_src/EarthVQA/result.png" class="img-responsive" alt="overview"><br></image> -->
                <image src="research_src/PromptKnow/Know_CAM.jpg" class="img-responsive" alt="overview"><br></image>
                <image src="research_src/PromptKnow/radar_plot2.png" class="img-responsive" alt="overview"><br></image>
                <!-- <image src="research_src/PromptKnow/CV.jpg" class="img-responsive" alt="overview"><br></image> -->


            </div>
        </div>





        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <pre data-role="codeBlock" data-info="text" class="language-text">
@article{shen2024ssmp, 
                    title={Adaptive Self-supporting Prototype Learning for Remote Sensing Few-Shot Semantic Segmentation},
                    url={}, 
                    DOI={}, 
                    author={Shen, Weihao and Ma, Ailong and Wang, Junjue and Zheng, Zhuo and Zhong, Yanfei}, 
                    year={}, 
                    month={},
                    volume={},
                    pages={}}

                </pre>
            </div>
        </div> -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <h3>
                    Acknowledgments
                </h3>
                This work was supported by National Natural Science Foundation of China under Grant Nos. 42325105,
                42071350, and 42171336. -->
                <br><br>
                The website template was borrowed from <a href="https://bowenc0221.github.io/">Bowen Cheng</a> and <a
                    href="http://mgharbi.com/">Michaël Gharbi</a>.
                <p></p>
            </div>
        </div>
    </div>

    </div>
</body>

</html>