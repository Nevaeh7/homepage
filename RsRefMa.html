<!DOCTYPE html>

<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>RSRefMa</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        img {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        table,
        th,
        td {
            border: 1px solid black;
            border-collapse: collapse;
        }
    </style>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- <base href="/"> -->

    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <link rel="icon" type="image/png"
        href="https://github.com/Junjue-Wang/FactSeg/blob/master/imgs/myicon.jpg?raw=true">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-3"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-110862391-3');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                RSRefMa: Visual State Space Models with Spiral Selective <br> Scan for Referring Remote Sensing Image Segmentation

                </br>
                <small>

                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        Weihao Shen
                    </li>
                    <li>
                        Ailong Ma
                    </li>
                    <li>
                        <a href="http://zhuozheng.top/">
                            Zhuo Zheng
                        </a>
                    </li>
                    <li>
                        <a href="https://junjue-wang.github.io/homepage/">
                            Junjue Wang
                        </a>
                    </li>
                    <li>
                        <a href="http://rsidea.whu.edu.cn/">
                            Yanfei Zhong
                        </a>
                    </li>

                </ul>
                <small>

                </small>
            </div>
        </div>


        <!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a
                            href="https://www.researchgate.net/publication/376519677_EarthVQA_Towards_Queryable_Earth_via_Relational_Reasoning-based_Remote_Sensing_Visual_Question_Answering">
                            <image src="research_src/EarthVQA/paper_overview.png" height="120px"></image><br>
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a
                            href="https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-01-08/qd43oo1/Poster-AAAI.pdf">
                            <image src="research_src/EarthVQA/poster.png" height="120px"></image><br>
                            <h4><strong>Poster</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a
                            href="https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-01-08/2q83o0t/EarthVQA-video.mp4">
                            <image src="research_src/EarthVQA/video.png" height="120px"></image><br>
                            <h4><strong>Video</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div> -->


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <!-- <image src="research_src/EarthVQA/dataset_vis.png" class="img-responsive" alt="overview"><br></image>
                <image src="research_src/EarthVQA/framework.png" class="img-responsive" alt="overview"><br></image> -->
                <!-- <p class="text-justify">This is follow-up work of our <a
                        href="https://Junjue-Wang.github.io/homepage/LoveDA" style="color: #0000cc">LoveDA
                        (NeurIPS2021)</a>
                </p> -->
                <p class="text-justify">
                    Remote sensing image segmentation (RRSIS) aims to recognize ground targets in relevant areas of remote sensing images based on language. It is challenging and has significant research importance. Traditional referring image segmentation (RIS) frameworks primarily rely on multimodal feature fusion and decoders based on convolutional neural networks or transformers. These frameworks face challenges in aligning ground targets and language modalities across complex spatial scales and achieving fine-grained segmentation of tiny regions of interest. We propose the Spiral Selective Scan Visual State Space Model (RSRefMa), which enhances the alignment of visual and language features from the perspective of enhancing global contextual multimodal understanding. Specifically, we introduce a state space model based on spiral scanning to capture globally representative visual features, improving the model's comprehension of visual and language modalities and ensuring precise alignment between them. Additionally, to address the difficulty of fine-grained segmentation of tiny, weak targets, we integrate dual multi-scale visual prompts with language prompts, enabling a comprehensive representation of foreground and background features for accurate boundary segmentation. Extensive experiments on two referring remote sensing image segmentation datasets demonstrate that our proposed RSRefMa method has superior understanding and segmentation performance compared to previous state-of-the-art methods.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                
                <h3>
                    Problems and Solutions
                </h3>

                <image src="research_src/RSRefMa/Motivation.jpg" class="img-responsive" alt="overview"><br></image>
               
                <h3>
                    Method
                </h3>

                <image src="research_src/RSRefMa/RSRefMa.jpg" class="img-responsive" alt="overview"><br></image>

                <h3>
                    Experiments
                </h3>
                <!-- <image src="research_src/EarthVQA/result.png" class="img-responsive" alt="overview"><br></image> -->
                <image src="research_src/RSRefMa/VIZ.jpg" class="img-responsive" alt="overview"><br></image>
                <image src="research_src/RSRefMa/ATTN2.jpg" class="img-responsive" alt="overview"><br></image>
                <!-- <image src="research_src/PromptKnow/CV.jpg" class="img-responsive" alt="overview"><br></image> -->


            </div>
        </div>





        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <pre data-role="codeBlock" data-info="text" class="language-text">
@article{shen2024ssmp, 
                    title={Adaptive Self-supporting Prototype Learning for Remote Sensing Few-Shot Semantic Segmentation},
                    url={}, 
                    DOI={}, 
                    author={Shen, Weihao and Ma, Ailong and Wang, Junjue and Zheng, Zhuo and Zhong, Yanfei}, 
                    year={}, 
                    month={},
                    volume={},
                    pages={}}

                </pre>
            </div>
        </div> -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <h3>
                    Acknowledgments
                </h3>
                This work was supported by National Natural Science Foundation of China under Grant Nos. 42325105,
                42071350, and 42171336. -->
                <br><br>
                The website template was borrowed from <a href="https://bowenc0221.github.io/">Bowen Cheng</a> and <a
                    href="http://mgharbi.com/">MichaÃ«l Gharbi</a>.
                <p></p>
            </div>
        </div>
    </div>

    </div>
</body>

</html>